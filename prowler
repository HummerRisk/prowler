#!/usr/bin/env bash

# Copyright 2018 Toni de la Fuente

# Prowler is a tool that provides automate auditing and hardening guidance of an
# AWS account. It is based on AWS-CLI commands. It follows some guidelines
# present in the CIS Amazon Web Services Foundations Benchmark at:
# https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf

# Contact the author at https://blyx.com/contact
# and open issues or ask questions at https://github.com/prowler-cloud/prowler

# Code is licensed as Apache License 2.0 as specified in
# each file. You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0

# Prowler - Iron Maiden
#
# Walking through the city, looking oh so pretty
# I've just got to find my way
# See the ladies flashing
# All there legs and lashes
# I've just got to find my way...

# Set the defaults variables
PROWLER_VERSION=2.10.0-25May2022
PROWLER_DIR=$(dirname "$0")

# DEPENDENCIES
. $PROWLER_DIR/include/colors
. $PROWLER_DIR/include/os_detector
. $PROWLER_DIR/include/aws_profile_loader
. $PROWLER_DIR/include/awscli_detector
. $PROWLER_DIR/include/whoami
. $PROWLER_DIR/include/assume_role
. $PROWLER_DIR/include/csv_header
. $PROWLER_DIR/include/banner
. $PROWLER_DIR/include/html_report
. $PROWLER_DIR/include/jq_detector
. $PROWLER_DIR/include/outputs_bucket
. $PROWLER_DIR/include/outputs
. $PROWLER_DIR/include/credentials_report
. $PROWLER_DIR/include/scoring
. $PROWLER_DIR/include/secrets_detector
. $PROWLER_DIR/include/check_creds_last_used
. $PROWLER_DIR/include/check3x
. $PROWLER_DIR/include/connection_tests
. $PROWLER_DIR/include/securityhub_integration
. $PROWLER_DIR/include/junit_integration
. $PROWLER_DIR/include/organizations_metadata
. $PROWLER_DIR/include/custom_checks
. $PROWLER_DIR/include/allowlist
. $PROWLER_DIR/include/db_connector

# USAGE
usage(){
  echo "
USAGE:
      `basename $0` [ -p <profile> -r <region>  -h ]
  Options:
      -p <profile>        Specify your AWS profile to use.
                            (i.e.: default)
      -r <region>         Specify an AWS region to direct API requests to.
                            (i.e.: us-east-1), all regions are checked anyway if the check requires it.
      -c <check_id>       Specify one or multiple check ids separated by commas, to see all available checks use "-l" option.
                            (i.e.: "check11" for check 1.1 or "extra71,extra72" for extra check 71 and extra check 72)
      -C                  Checklist file. See checklist.txt for reference and format.
                            (i.e.: checklist.txt)
      -g <group_id>       Specify a group of checks by id, to see all available group of checks use "-L".
                            (i.e.: "group3" for entire section 3, "cislevel1" for CIS Level 1 Profile Definitions or "forensics-ready")
      -f <filterregion>   Specify an AWS region to run checks against.
                            (i.e.: us-west-1 or for multiple regions use single quote like 'us-west-1 us-west-2')
      -m <maxitems>       Specify the maximum number of items to return for long-running requests (default: 100).
      -M <mode>           Output or report mode: text (default), mono, html, json, json-asff, junit-xml, csv. They can be used combined comma separated.
                            (i.e.: "html,json"; files created in background; progress on stdout)
      -k                  Keep the credential report for debugging.
      -n                  Show check numbers to sort easier.
                            (i.e.: 1.01 instead of 1.1)
      -l                  List all available checks only (does not perform any check). Add -g <group_id> to only list checks within the specified group.
      -L                  List all groups (does not perform any check).
      -e                  Exclude group extras.
      -E                  Execute all tests except a list of specified checks separated by comma.
                            (i.e. check21,check31)
      -b                  Do not print Prowler banner.
      -s                  Show scoring report (it is included by default in the html report).
      -S                  Send check output to AWS Security Hub. Only valid when the output mode is json-asff
                            (i.e. "-M json-asff -S").
      -x                  Specify external directory with custom checks. S3 URI is supported.
                            (i.e. /my/own/checks or s3://bucket/prefix/checks, files must start by "check").
      -q                  Get only FAIL findings, will show WARNINGS when a resource is excluded.
      -A                  Account id for the account where to assume a role, requires -R.
                            (i.e.: 123456789012)
      -R                  Role name or role arn to assume in the account, requires -A.
                            (i.e.: ProwlerRole)
      -T                  Session duration given to that role credentials in seconds, default 1h (3600) recommended 12h, optional with -R and -A.
                            (i.e.: 43200)
      -I                  External ID to be used when assuming roles (not mandatory), requires -A and -R.
      -w                  Allowlist file. See allowlist_sample.txt for reference and format. S3 URI is supported.
                            (i.e.: allowlist_sample.txt or s3://bucket/prefix/allowlist_sample.txt)
      -N <shodan_api_key> Shodan API key used by check extra7102.
      -o                  Custom output directory, if not specified will use default prowler/output, requires -M <mode>.
                            (i.e.: -M csv -o /tmp/reports/)
      -B                  Custom output bucket, requires -M <mode> and it can work also with -o flag.
                            (i.e.: -M csv -B my-bucket or -M csv -B my-bucket/folder/)
      -D                  Same as -B but do not use the assumed role credentials to put objects to the bucket, instead uses the initial credentials.
      -F                  Custom output report name, if not specified will use default output/prowler-output-ACCOUNT_NUM-OUTPUT_DATE.format.
      -z                  Failed checks do not trigger exit code 3.
      -Z                  Specify one or multiple check ids separated by commas that will trigger exit code 3 if they fail. Unspecified checks will not trigger exit code 3. This will override "-z".
                            (i.e.: "-Z check11,check12" will cause check11 and/or check12 to trigger exit code 3)
      -O <mgmnt acct ID>  Specify AWS Organizations management account ID. Used to get account details, requires -R.
                            (requires organizations:ListAccounts* and organizations:ListTagsForResource)
      -a <aws_cli_cmd>    Build your own on-the-fly custom check by specifying the AWS CLI command to execute. Requires "-c extra9999". Omit the "aws" command and only use its parameters within quotes.
                          Do not nest quotes in the aws parameter. Note that --output text is already included in the check.
                            i,e. -a 'ec2 describe-security-groups --filters Name=ip-permission.to-port,Values=80 --query SecurityGroups[*].GroupId[]]'
      -V                  Show version number & exit.
      -h                  This help.
      -d                  Send output to database through database connectors supported, currently only PostgreSQL. Prowler will get the credentials and table name from your ~/.pgpass file.
  "
  exit
}

OPTRED="[1;31m"
OPTNORMAL="[0;39m"
REGION=""
FILTERREGION=""
MAXITEMS=100
MONOCHROME=0
MODE="text"
QUIET=0
SEP=','
KEEPCREDREPORT=0
EXITCODE=0
SEND_TO_SECURITY_HUB=0
FAILED_CHECK_FAILED_SCAN=1
PROWLER_START_TIME=$( date -u +"%Y-%m-%dT%H:%M:%S%z" )
OUTPUT_DATE=$(date -u +"%Y%m%d%H%M%S")
TITLE_ID=""
TITLE_TEXT="CALLER ERROR - UNSET TITLE"
ALLOWLIST_FILE=""
TOTAL_CHECKS=()

# This function comes from include/awscli_detector
set_aws_default_output

############################################################################################
# Function to show the title of a group, by numeric id
show_group_title() {
  textTitle "${GROUP_NUMBER[$1]}" "${GROUP_TITLE[$1]}"
}

# REVIEW
show_all_group_titles() {
  local group_index
  for group_index in "${!GROUP_TITLE[@]}"; do
    show_group_title "$group_index"
  done
}

############################################################################################

load_groups() {
  # Load all of the groups of checks inside groups folder named as "groupNumber*"
for group in $(ls $PROWLER_DIR/groups/group[0-9]*|grep -v groupN_sample); do
	. "$group"
done
}

load_check(){
  CHECK=${1}

  # load the check
  . "$PROWLER_DIR/checks/${CHECK}"
}

get_checks() {
# get all of the checks inside checks folder named as "check*"
# this includes also extra checks since they are "check_extraNN
# If '-g <group_id>' has been specified, only show the titles of checks within the specified group
  # reading groups from GROUP_ID_READ
  # Now we can read groups comma or space splitted

#Parsing input options
# Parses the check file into CHECK_ID's.
if [[ -n "$CHECK_FILE" ]]
then
  if [[ -f $CHECK_FILE ]]
  then
    # Parses the file, converting it to a comma seperated list. Ignores all # comments and removes extra blank spaces
    # REVIEW THIS OPTION -C
    TOTAL_CHECKS="$(awk '!/^[[:space:]]*#/{print }' <(cat ${CHECK_FILE} | sed 's/[[:space:]]*#.*$//g;/^$/d' | sed 'H;1h;$!d;x;y/\n/,/' | tr -d ' '))"
  else
    # If the file doesn't exist, exits Prowler
    echo "$CHECK_FILE does not exist"
    EXITCODE=1
    exit $EXITCODE
  fi
elif [[ "${GROUP_ID_READ}" ]]
then
  for GROUP in "${GROUP_ID[@]}"
  do
    if [[ "${GROUP}" == "${GROUP_ID_READ}" ]]
    then
      IS_GROUP=1
    fi
  done
  if [[ IS_GROUP -eq 0 ]]
  then
      textFail "Group ${GROUP_ID_READ} does not exist. Valid check groups are: ${GROUP_ID[*]}"
      exit $EXITCODE
  fi
  # Iterate over every group removing echar comma
  for GROUP_IDENTIFIER in ${GROUP_ID_READ//,/ }
  do
    # Iterate over every GroupID to find the belongin checks
    for I in "${!GROUP_ID[@]}"
    do
      if [[ "${EXTRAS}" -eq 1 && "${GROUP_ID[I]}" == "extras" ]]
      then
        continue
      else
        if [[ "${GROUP_ID[I]}" == "${GROUP_IDENTIFIER}" ]]
        then
          # shellcheck disable=SC2068
          for CHECK_IDENTIFIER in ${GROUP_CHECKS[I]//,/ }
          do
            # Include every check if not present
            if [[ ! "${CHECK_LIST_BY_GROUP[*]}" =~ ${CHECK_IDENTIFIER} ]] && ! grep -E -w -q "${EXCLUDE_CHECK_ID//,/|}" <<< "${CHECK_IDENTIFIER}"
            then
              CHECK_LIST_BY_GROUP+=("${CHECK_IDENTIFIER}")
            fi
          done
        fi
      fi
    done
  done
  TOTAL_CHECKS=("${CHECK_LIST_BY_GROUP[@]}")
elif [ -n "${CHECK_ID}" ]
then
    IFS=',' read -ra TOTAL_CHECKS <<< "${CHECK_ID}"
else
  # if -e is passed we dont want extra checks
  if [[ "${EXTRAS}" -eq 1 ]]
    then
      EXCLUDE_CHECK_ID=("${EXCLUDE_CHECK_ID[@]}" "${GROUP_CHECKS[7]}")
  fi
  for CHECK in $(ls $PROWLER_DIR/checks/check*|grep -v check_sample); do
	  # Relative path required to load every check
    CHECK_DIR_NAME=$(basename "${CHECK}")
    # Name of the check
    CHECK_NAME=${CHECK_DIR_NAME//check_/}
    # If a group identifier is passed

    if ! grep -E -w -q "${EXCLUDE_CHECK_ID//,/|}" <<< "${CHECK_NAME}"
    then
      TOTAL_CHECKS+=("${CHECK_NAME}")
    fi

  done
fi

# Iterate over the final list of checks after being parsed all the input options to load the selected checks
for LOAD_PATH_CHECK in ${TOTAL_CHECKS[*]}
do
    # If the check is extra, the path needs to add check_ after the check name
    if [[ "${LOAD_PATH_CHECK}" =~ 'extra' ]]
    then
        LOAD_PATH_CHECK=${LOAD_PATH_CHECK/#/check_}
    fi
    load_check "${LOAD_PATH_CHECK}"
done

}

############################################################################################



############################################################################################

is_check_in_group() {
  CHECK_ID="${1}"
  GROUP_ID="${2}"
  # la variable que almacena todos los checks contenidos es esta lista GROUP_CHECKS[N]
}

# Function to show the titles of either all checks or only those in the specified group
show_all_check_titles() {
  local CHECK_LIST_BY_GROUP
  local check_id
  local group_index

  for CHECK_ID in ${TOTAL_CHECKS[*]}
  do
    show_check_title "${CHECK_ID}"
  done

  exit

}

# Function to show the title of the check, and optionally which group(s) it belongs to
# using this way instead of arrays to keep bash3 (osx) and bash4(linux) compatibility
show_check_title() {
  local check_id=CHECK_ID_$1
  local check_title=CHECK_TITLE_$1
  local check_scored=CHECK_SCORED_$1
  local check_cis_level=CHECK_CIS_LEVEL_$1
  local check_asff_compliance_type=CHECK_ASFF_COMPLIANCE_TYPE_$1
  local check_severity=CHECK_SEVERITY_$1
  local check_servicename=CHECK_SERVICENAME_$1
  local group_ids
  local group_index

  # This shows ASFF_COMPLIANCE_TYPE if group used is ens, this si used to show ENS compliance ID control, can be used for other compliance groups as well.
  if [[ ${GROUP_ID_READ} == "ens" ]];then
    textTitle "${!check_id}" "${!check_title}" "${!check_scored}" "${!check_cis_level}" "$group_ids" "(${!check_asff_compliance_type})"
  else
    textTitle "${!check_id}" "${!check_title}" "${!check_servicename}" "${!check_severity}" "$group_ids" "${!check_cis_level}"
  fi
}

############################################################################################
while getopts ":hlLkqp:r:c:C:g:f:m:M:E:x:enbVsSI:A:R:T:w:N:o:B:D:F:zZ:O:a:d:" OPTION; do
   case $OPTION in
     h )
        usage
        EXITCODE=1
        exit $EXITCODE
        ;;
     l )
        LIST_CHECKS=1
        ;;
     L )
        LIST_GROUPS=1
        ;;
     k )
        KEEPCREDREPORT=1
        ;;
     p )
        PROFILE=$OPTARG
        AWS_PROFILE=$OPTARG
        ;;
     r )
        REGION_OPT=$OPTARG
        ;;
     c )
        CHECK_ID=$OPTARG
        ;;
     C )
        CHECK_FILE=$OPTARG
        ;;
     g )
        GROUP_ID_READ=$OPTARG
        ;;
     f )
        FILTERREGION=$OPTARG
        ;;
     m )
        MAXITEMS=$OPTARG
        ;;
     M )
        MODE=$OPTARG
        ;;
     n )
        NUMERAL=1
        ;;
     b )
        BANNER=0
        ;;
     e )
        EXTRAS=1
        ;;
     E )
        EXCLUDE_CHECK_ID=$OPTARG
        ;;
     V )
        echo "Prowler $PROWLER_VERSION"
        EXITCODE=0
        exit $EXITCODE
        ;;
     s )
        SCORING=1
        ;;
     S )
        SEND_TO_SECURITY_HUB=1
        ;;
     x )
        EXTERNAL_CHECKS_PATH=$OPTARG
        ;;
     q )
        QUIET=1
        ;;
     A )
        ACCOUNT_TO_ASSUME=$OPTARG
        ;;
     R )
        ROLE_TO_ASSUME=$OPTARG
        ;;
     I )
        ROLE_EXTERNAL_ID=$OPTARG
        ;;
     T )
        SESSION_DURATION_TO_ASSUME=$OPTARG
        ;;
     w )
        ALLOWLIST_FILE=$OPTARG
        ;;
     N )
        SHODAN_API_KEY=$OPTARG
        ;;
     o )
        OUTPUT_DIR_CUSTOM=$OPTARG
        ;;
     B )
        OUTPUT_BUCKET=$OPTARG
        ;;
     D )
        OUTPUT_BUCKET=$OPTARG
        OUTPUT_BUCKET_NOASSUME=1
        ;;
     F )
        OUTPUT_FILE_NAME=$OPTARG
        ;;
     z )
        FAILED_CHECK_FAILED_SCAN=0
        ;;
     Z )
        FAILED_CHECK_FAILED_SCAN_LIST=$OPTARG
        ;;
     O )
        MANAGEMENT_ACCOUNT_ID=$OPTARG
        ;;
     a )
        CUSTOM_CMD=$OPTARG
        ;;
     d )
        DATABASE_PROVIDER=$OPTARG
        ;;
     : )
        echo ""
        echo "$OPTRED ERROR!$OPTNORMAL  -$OPTARG requires an argument"
        usage
        EXITCODE=1
        exit $EXITCODE
        ;;
     ? )
        echo ""
        echo "$OPTRED ERROR!$OPTNORMAL Invalid option"
        usage
        EXITCODE=1
        exit $EXITCODE
        ;;
   esac
done

load_groups
get_checks

if [[ ${LIST_CHECKS} -eq 1 ]]; then
  show_all_check_titles
fi

if [[ ${LIST_GROUPS} -eq 1 ]]; then
  show_all_group_titles
fi

clean_up() {
  rm -f /tmp/prowler*.policy.*
  # in case html output is used, make sure it closes html file properly
  if [[ "${MODES[@]}" =~ "html" ]]; then
    addHtmlFooter >> ${OUTPUT_FILE_NAME}.$EXTENSION_HTML
  fi
  # puts the AWS_DEFAULT_OUTPUT back to what it was at the start
  if [ -z "$ORIGINAL_OUTPUT" ]; then
    export AWS_DEFAULT_OUTPUT="$ORIGINAL_OUTPUT"
  else
    unset AWS_DEFAULT_OUTPUT
  fi
}

handle_ctrl_c() {
  clean_up
  exit $EXITCODE
}

# Clean up any temp files when prowler quits unexpectedly
trap clean_up EXIT
# Clean up and exit if Ctrl-C occurs. Required to allow Ctrl-C to stop Prowler when running in Docker
trap handle_ctrl_c INT

# Environment variable takes precedence over command line
unset AWS_DEFAULT_OUTPUT

# Check OS
os_detector
TIMESTAMP=$(get_iso8601_timestamp)

# Check database providers
if [[ ${DATABASE_PROVIDER} ]]
then
    # Check if input provider is supported
    if ! grep -w -q -E "${DATABASE_PROVIDER}" <<< "${SUPPORTED_DB_PROVIDERS}"
    then
        db_exit_abnormally "${DATABASE_PROVIDER}" "DB provider not supported, providers supported: ${SUPPORTED_DB_PROVIDERS} - EXITING!"
    elif ! command -v "psql" > /dev/null 2>&1
    then
        db_exit_abnormally "postgresql" "psql tool not installed or not found- EXITING!"
    elif  [[ $(find "${HOME}/.pgpass" -perm 600 2>/dev/null) != "$HOME/.pgpass" ]]
    then
          db_exit_abnormally  "postgresql" ".pgpass file not found at $HOME/.pgpass or .pgpass file permissions not matching 600 - EXITING!"
    else
        IFS=':' read -r PSQL_HOSTNAME PSQL_PORT PSQL_DATABASE PSQL_USER PSQL_PASSWORD PSQL_TABLE < "$HOME/.pgpass"
        if [[ ! ${PSQL_HOSTNAME} ]] || [[ ! ${PSQL_PORT} ]] || [[ ! ${PSQL_DATABASE} ]] || [[ ! ${PSQL_USER} ]] || [[ ! ${PSQL_PASSWORD} ]] || [[ ! ${PSQL_TABLE} ]]
        then
             db_exit_abnormally "postgresql" "Empty field into ${HOME}/.pgpass file, all fields must be filled. Please check Prowler README about .pgpass file format - EXITING!"
        fi
        export PSQL_USER
        export PSQL_HOSTNAME
        export PSQL_TABLE

        # Once all the variables are defined and exported test if database instance is reachable
        if ! pg_isready -q  -U "${PSQL_USER}" -h "${PSQL_HOSTNAME}" -p "${PSQL_PORT}"
        then
            db_exit_abnormally "postgresql" "Database listening on host ${PSQL_HOSTNAME} on port ${PSQL_PORT} connected as user ${PSQL_USER} is unreachable - EXITING!"
        # If database instance is ready time to check credentials
        elif ! PGPASSWORD="${PSQL_PASSWORD}" psql -U "${PSQL_USER}" -h "${PSQL_HOSTNAME}" -c "\q" > /dev/null  2>&1
        then
            db_exit_abnormally "postgresql" "User ${PSQL_USER} invalid or invalid credentials, please check ${HOME}/.pgpass file - EXITING!"
        # If credentials are ok -> database exists?
        elif ! PGPASSWORD="${PSQL_PASSWORD}" psql -U "${PSQL_USER}" -h "${PSQL_HOSTNAME}" "${PSQL_DATABASE}" -c "\q" > /dev/null  2>&1
        then
            db_exit_abnormally "postgresql" "Database not exists, please check ${HOME}/.pgpass file - EXITING!"
        # and finally, if database exists -> table exists ?
        elif ! PGPASSWORD="${PSQL_PASSWORD}" psql -U "${PSQL_USER}" -h "${PSQL_HOSTNAME}" "${PSQL_DATABASE}"  -c "SELECT * FROM ${PSQL_TABLE};" > /dev/null  2>&1
        then
             db_exit_abnormally "postgresql" "Table ${PSQL_TABLE} not exists, please check ${HOME}/.pgpass file - EXITING!"
        fi


    fi
fi

# Check modes
# POSSIBLE FUNCTION HERE
# REVIEW
if [ -n "${MODE}" ]
then
  AVAILABLE_OUTPUT_MODES="mono|text|csv|json|json-asff|junit-xml|html"
  IFS=',' read -ra MODES <<< "${MODE}"
  for MODE in "${MODES[@]}"; do
    if ! grep -w -q -E "${AVAILABLE_OUTPUT_MODES}" <<< "${MODE}"
    then
      echo -e "${OPTRED}ERROR!$OPTNORMAL Invalid output mode. Choose text, mono, csv, json, json-asff, junit-xml or html. ./prowler -h for help"
      EXITCODE=1
      exit $EXITCODE
    fi
  done
fi

#Check output dir custom
if [ -n "${OUTPUT_DIR_CUSTOM}" ]
then
    # If dir custom, mode has to be enabled (if you provide a custom directory it's because you want to store something)
    if [  "${MODE}" != 'text' ]
    then
        # Check if custom folder exists
        if [ ! -d "${OUTPUT_DIR_CUSTOM}" ]
        then
            echo "$OPTRED ERROR!$OPTNORMAL directory \"$OUTPUT_DIR_CUSTOM\" does not exist."
            exit 1
        else
            OUTPUT_DIR=$OUTPUT_DIR_CUSTOM
        fi
    else
        echo "$OPTRED ERROR!$OPTNORMAL - When using custom directory output Mode (-M) has to be set as well. Use -h for help."
        exit 1
    fi
 # If custom output dir is not provided output dir -> default
 else
        OUTPUT_DIR="${PROWLER_DIR}/output"
        if [ ! -d "${OUTPUT_DIR}" ]
        then
            mkdir -p "${OUTPUT_DIR}"
        fi
 fi

 # End of input parameters tests

# Pre-process allowlist file if supplied
if [[ -n "$ALLOWLIST_FILE" ]]; then
  allowlist
fi

# Create output file name
if [ -n "${OUTPUT_FILE_NAME}" ]
then
  OUTPUT_FILE_NAME="${OUTPUT_DIR}/$OUTPUT_FILE_NAME"
else
  OUTPUT_FILE_NAME="${OUTPUT_DIR}/prowler-output-${ACCOUNT_NUM}-${OUTPUT_DATE}"
fi

# Output bucket parsing input checking
if [[ $OUTPUT_BUCKET ]]; then
  # output mode has to be set to other than text
  if [[ "${MODES[*]}" =~ "text" ]]; then
    echo "$OPTRED ERROR!$OPTNORMAL - Mode (-M) can't be text when using custom output bucket. Use -h for help."
    exit 1
  else
    # need to make sure last / is not set to avoid // in S3
    if [[ $OUTPUT_BUCKET == *"/" ]]; then
      OUTPUT_BUCKET=${OUTPUT_BUCKET::-1}
    fi
  fi
fi

# Add headers to certain output files
output_files_init

# include checks if external folder is specified
# REVIEW
if [[ $EXTERNAL_CHECKS_PATH ]]; then
  custom_checks
fi

# Function to get all regions
get_regions() {
  # Get list of regions based on include/whoami
  if ! REGIONS=$($AWSCLI ec2 describe-regions \
            --query 'Regions[].RegionName' \
            --output text ${PROFILE_OPT} \
            --region "${REGION_FOR_STS}" \
            --region-names ${FILTERREGION//[,]/ } 2>&1)
  then
    echo "$OPTRED Access Denied trying to describe regions! Review permissions as described here: https://github.com/prowler-cloud/prowler/#requirements-and-installation $OPTNORMAL"
    EXITCODE=1
    exit $EXITCODE
  fi
}


# Function to execute the check
execute_check() {
  if [[ -n "${ACCOUNT_TO_ASSUME}" || -n "${ROLE_TO_ASSUME}" ]]; then
    # echo ******* I am here again to check on my role *******
    # Following logic looks for time remaining in the session and review it
    # if it is less than 600 seconds, 10 minutes.
    CURRENT_TIMESTAMP=$(date -u "+%s")
    SESSION_TIME_REMAINING=$(expr $AWS_SESSION_EXPIRATION - $CURRENT_TIMESTAMP)
    # echo SESSION TIME REMAINING IN SECONDS: $SESSION_TIME_REMAINING
    MINIMUM_REMAINING_TIME_ALLOWED=600
    if (( $MINIMUM_REMAINING_TIME_ALLOWED > $SESSION_TIME_REMAINING )); then
      # echo LESS THAN 10 MIN LEFT: RE-ASSUMING...
      unset AWS_ACCESS_KEY_ID
      unset AWS_SECRET_ACCESS_KEY
      unset AWS_SESSION_TOKEN
      assume_role
    fi
  fi

  CHECK_ID="$1"

  # See if this is an alternate name for a check
  # for example, we might have been passed 1.01 which is another name for 1.1
  local alternate_name_var=CHECK_ALTERNATE_$1
  local alternate_name=${!alternate_name_var}
  # See if this check defines an ASFF Type, if so, use this, falling back to a sane default
  # For a list of Types Taxonomy, see: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-findings-format-type-taxonomy.html
  local asff_type_var=CHECK_ASFF_TYPE_$1
  CHECK_ASFF_TYPE="${!asff_type_var:-Software and Configuration Checks}"

  local asff_compliance_type_var=CHECK_ASFF_COMPLIANCE_TYPE_$1
  CHECK_ASFF_COMPLIANCE_TYPE="${!asff_compliance_type_var:-Software and Configuration Checks}"

  # See if this check defines an ASFF Resource Type, if so, use this, falling back to a sane default
  # For a list of Resource Types, see: https://docs.aws.amazon.com/securityhub/latest/userguide/securityhub-findings-format.html#asff-resources
  local asff_resource_type_var=CHECK_ASFF_RESOURCE_TYPE_$1
  CHECK_ASFF_RESOURCE_TYPE="${!asff_resource_type_var:-AwsAccount}"

  local severity_var=CHECK_SEVERITY_$1
  CHECK_SEVERITY="${!severity_var}"

  local servicename_var=CHECK_SERVICENAME_$1
  CHECK_SERVICENAME="${!servicename_var}"

  local risk_var=CHECK_RISK_$1
  CHECK_RISK="${!risk_var}"

  local remediation_var=CHECK_REMEDIATION_$1
  CHECK_REMEDIATION="${!remediation_var}"

  local doc_var=CHECK_DOC_$1
  CHECK_DOC="${!doc_var}"

  local caf_epic_var=CHECK_CAF_EPIC_$1
  CHECK_CAF_EPIC="${!caf_epic_var}"

  SECURITYHUB_NEW_FINDINGS_IDS=()

  # Generate the credential report, only if it is group1 related which checks we
  # run so that the checks can safely assume it's available
  # set the custom ignores list for this check
  ignores="$(awk "/${1}/{print}" <(echo "${ALLOWLIST}"))"

  if [ ${alternate_name} ];then
    if [[ ${alternate_name} == check1* || ${alternate_name} == extra71 || ${alternate_name} == extra774 || ${alternate_name} == extra7123 ]];then
      if [ ! -s $TEMP_REPORT_FILE ];then
        genCredReport
        saveReport
      fi
    fi
    show_check_title ${alternate_name}
    if is_junit_output_enabled; then
      prepare_junit_check_output "$1"
    fi
    # Execute the check
    IGNORES="${ignores}" CHECK_NAME="$1" ${alternate_name}
    if is_junit_output_enabled; then
      finalise_junit_check_output "$1"
    fi

    if [[ "$SEND_TO_SECURITY_HUB" -eq 1 ]]; then
      resolveSecurityHubPreviousFails "$1"
    fi
  else
    # Check to see if this is a real check
    local check_id_var=CHECK_ID_$1
    local check_id=${!check_id_var}
    if [ ${check_id} ]; then
      if [[ ${check_id} == 1* || ${check_id} == 7.1 || ${check_id} == 7.74 || ${check_id} == 7.123 ]];then
        if [ ! -s $TEMP_REPORT_FILE ];then
          genCredReport
          saveReport
        fi
      fi
      show_check_title "$1"
      if is_junit_output_enabled; then
        prepare_junit_check_output "$1"
      fi
      # Execute the check
      IGNORES="${ignores}" CHECK_NAME="$1" $1

      if is_junit_output_enabled; then
        finalise_junit_check_output "$1"
      fi

      if [[ "$SEND_TO_SECURITY_HUB" -eq 1 ]]; then
        resolveSecurityHubPreviousFails "$1"
      fi

    else
      textFail "Check ${CHECK_ID} does not exist. Use a valid check name (i.e. check41 or extra71)";
      exit $EXITCODE
    fi
  fi
}

# REVIEW MOVER
prowlerBanner

# Check that jq is installed for JSON outputs
if [[ "${MODES[*]}" =~ "json" || "${MODES[*]}" =~ "json-asff" ]]
then
  jq_detector
fi

# Check AWS CLI
aws_cli_detector
# aws_profile_loader
aws_profile_loader

if [[ "$SEND_TO_SECURITY_HUB" -eq 1 ]]
then
  checkSecurityHubCompatibility
fi

if is_junit_output_enabled
then
  prepare_junit_output
fi

# First, check AWS Organizations Metadata
if [[ -n "${MANAGEMENT_ACCOUNT_ID}" && -n "${ROLE_TO_ASSUME}" ]]
then
  # Backing up initial credentials
  backupInitialAWSCredentials

  # Backing up initial account to assume
  INITIAL_ACCOUNT_TO_ASSUME="${ACCOUNT_TO_ASSUME}"

  # Set the new account to assume to recover AWS Organizations Metadata
  ACCOUNT_TO_ASSUME="${MANAGEMENT_ACCOUNT_ID}"

  # Recover AWS Organizations Metadata
  get_orgs_account_details

  # Restoring account to assume to -A field after getting account metadata
  ACCOUNT_TO_ASSUME="${INITIAL_ACCOUNT_TO_ASSUME}"

  # Restoring initial credentials
  restoreInitialAWSCredentials
fi

if [[ -n "${ACCOUNT_TO_ASSUME}" || -n "${ROLE_TO_ASSUME}" ]]
then
  backupInitialAWSCredentials
  assume_role
fi


case "$REGION" in
  me-south-1|eu-south-1|ap-east-1|af-south-1)
    REGION_FOR_STS="us-east-1"
  ;;
  *)
    REGION_FOR_STS=$REGION
  ;;
esac

if ! GETCALLER=$("${AWSCLI}" sts get-caller-identity \
                  ${PROFILE_OPT} \
                --output text \
                --region "${REGION_FOR_STS}" \
                --query '[Arn,UserId,Account]')
then
    echo -e "$RED ERROR Getting credentials to run Prowler - EXITING! $NORMAL"
    EXITCODE=2
    exit $EXITCODE
fi
read -r CALLER_ARN USER_ID ACCOUNT_NUM <<< "${GETCALLER}"

if [[ $ACCOUNT_TO_ASSUME ]]
then
  ACCOUNT_NUM=$ACCOUNT_TO_ASSUME
fi
AWS_PARTITION=$(cut -d: -f2 <<< "${CALLER_ARN}")

# Gather account data / test aws cli connectivity
getWhoami

# List regions
get_regions

for CHECK in "${TOTAL_CHECKS[@]}"
do
  execute_check $CHECK
done

if [[ "${MODES[@]}" =~ "html" ]]; then
  addHtmlFooter >> ${OUTPUT_FILE_NAME}.$EXTENSION_HTML
fi
if [[ $OUTPUT_BUCKET_NOASSUME ]]; then
  restoreInitialAWSCredentials
fi
if [[ $OUTPUT_BUCKET ]]; then
  copyToS3
fi
scoring
cleanTemp
exit $EXITCODE
